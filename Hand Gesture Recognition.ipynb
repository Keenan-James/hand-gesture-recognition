{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/dc-aihub/dc-aihub.github.io/blob/master/img/ai-logo-transparent-banner.png?raw=true\" \n",
    "alt=\"Ai/Hub Logo\"/>\n",
    "\n",
    "<h1 style=\"text-align:center;color:#0B8261;\"><center>Artificial Intelligence</center></h1>\n",
    "<h1 style=\"text-align:center;\"><center>Hand Gesture Recognition & The Importance of Image Pre-Processing </center></h1>\n",
    "\n",
    "<center>***Code and Original Tutorial written by Sadaival Singh:*** <br/>https://www.youtube.com/watch?v=v-XcmsYlzjA</center>\n",
    "\n",
    "<hr/>\n",
    "\n",
    "<center><a href=\"#OVERVIEW\">Overview</a></center>\n",
    "<center><a href=\"#PURPOSE\">Purpose</a></center>\n",
    "<center><a href=\"#IMAGE-PREPROCESSING\">Image Pre-Processing</a></center>\n",
    "<center><a href=\"#GETTING-STARTED\">Getting Started</a></center>\n",
    "<center><a href=\"#CONCLUSION\">Conclusion</a></center>\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#0B8261; width:100%; height:38px; color:white; font-size:18px; padding:10px;\" id=\"OVERVIEW\">\n",
    "OVERVIEW\n",
    "</div>\n",
    "\n",
    "\n",
    "For this exercise will create a program that will identify hand gestures in real time by streaming video from a webcam. The program will outline a hand within a given space on screen and then further determine the number of fingers that are showing which will give us our output. The possible hand gesture classes are as follows:\n",
    "\n",
    "\n",
    "- 1 finger\n",
    "- 2 fingers\n",
    "- 3 fingers \n",
    "- 4 fingers\n",
    "- 5 fingers\n",
    "- Ok \n",
    "- Good Job\n",
    "\n",
    "![](images/goodjob.png)\n",
    "\n",
    "<div style=\"background-color:#0B8261; width:100%; height:38px; color:white; font-size:18px; padding:10px;\" id=\"PURPOSE\">\n",
    "PURPOSE\n",
    "</div>\n",
    "\n",
    "\n",
    "Although in this exercise we will not be using an artificial intelligence network directly, our program will be able to capture and predict hand gestures with a high degree of accuracy using a programmatic solution. The value of the exercise in the context of AI is found in the practice and understanding of several image pre-processing techniques that could be invaluable when training a specialized neural network.\n",
    "\n",
    "\n",
    "As you will see below, our hard coded approach to gesture recognition is limited by methods found in the OpenCV package. And although this program preforms rather admirably in this context, it must be noted that only a neural network would allow for a greater range of classes and abstract recognition. For example; attempting to program logic that would capture and translate sign-language from raw video data would be nearly an impossible task, however, a neural network would be far better suited to rise to this challenge.\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"background-color:#0B8261; width:100%; height:38px; color:white; font-size:18px; padding:10px;\" id=\"IMAGE-PREPROCESSING\">\n",
    "IMAGE PRE-PROCESSING\n",
    "</div>\n",
    "\n",
    "\n",
    "So why bother pre-process visual data in the first place and not just feed a neural network an unfiltered image? The answer lies in understanding how neural networks make their decisions; using layers of nodes each with their own calculated weights and biases. For our model to work efficiently the nodes must be able to positively respond to data that is relevant to our problem and conversely ignore what is not needed. \n",
    "\n",
    "\n",
    "In this sense we can understand that training a neural network involves both training it what to recognize but also what not to recognize, and in our case; what is a hand and what is not a hand. We certainly do not want the neurons of our network activating by random background imagery that may appear in our data but is not the intended focus. This brings us to the importance of pre-processing image data as there are steps we can take to feed our model with data that is more relevant and specific to our problem, giving it only data that and has a stake in determining the final output. We can essentially help eliminate noise and unwanted information that has the potential of drastically minimizing the size and training resources needed by our model while maintaining a higher accuracy. \n",
    "\n",
    "\n",
    "Specifically in our case we take the following image pre-processing steps:\n",
    " \n",
    " \n",
    "- Select a boundary of the input image within which we will scan for the presence of a human hand. \n",
    "- Create a mask by selecting only pixels that match a specified colour range.\n",
    "- Blur the mask image to fill in missing data points.\n",
    "- Draw contour of the hand and identify fingers showing using tools from Open CV.\n",
    "\n",
    "\n",
    "<div style=\"background-color:#0B8261; width:100%; height:38px; color:white; font-size:18px; padding:10px;\" id=\"GETTING-STARTED\">\n",
    "GETTING STARTED\n",
    "</div>\n",
    "\n",
    "\n",
    "Start by reviewing the packages that are being imported and ensure you have the required dependencies installed. Also note that for this program to work you will need to have a functional webcam equipped. \n",
    "\n",
    "\n",
    "Before running the code understand that this program works by recognizing pixels of the image that fall within a specified range. This range we set below in the code using HSV values. If you are unfamiliar with HSV colour values please check out the site here to visualize the colour range we have chosen. For best performance please ensure the background your webcam sees is around you hand is a different colour than what falls within our range. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(1):\n",
    "        \n",
    "    try:  #an error comes if it does not find anything in window as it cannot find contour of max area\n",
    "          #therefore this try error statement\n",
    "          \n",
    "        ret, frame = cap.read()\n",
    "        frame=cv2.flip(frame,1)\n",
    "        kernel = np.ones((3,3),np.uint8)\n",
    "        \n",
    "        #define region of interest\n",
    "        roi=frame[100:300, 100:300]\n",
    "        \n",
    "        \n",
    "        cv2.rectangle(frame,(100,100),(300,300),(0,255,0),0)    \n",
    "        hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        \n",
    "         \n",
    "    # define range of skin color in HSV\n",
    "        lower_skin = np.array([0,20,70], dtype=np.uint8)\n",
    "        upper_skin = np.array([20,255,255], dtype=np.uint8)\n",
    "        \n",
    "     #extract skin colur imagw  \n",
    "        mask = cv2.inRange(hsv, lower_skin, upper_skin)\n",
    "        \n",
    "   \n",
    "        \n",
    "    #extrapolate the hand to fill dark spots within\n",
    "        mask = cv2.dilate(mask,kernel,iterations = 4)\n",
    "        \n",
    "    #blur the image\n",
    "        mask = cv2.GaussianBlur(mask,(5,5),100) \n",
    "        \n",
    "        \n",
    "        \n",
    "    #find contours\n",
    "        _,contours,hierarchy= cv2.findContours(mask,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "   #find contour of max area(hand)\n",
    "        cnt = max(contours, key = lambda x: cv2.contourArea(x))\n",
    "        \n",
    "    #approx the contour a little\n",
    "        epsilon = 0.0005*cv2.arcLength(cnt,True)\n",
    "        approx= cv2.approxPolyDP(cnt,epsilon,True)\n",
    "       \n",
    "        \n",
    "    #make convex hull around hand\n",
    "        hull = cv2.convexHull(cnt)\n",
    "        \n",
    "     #define area of hull and area of hand\n",
    "        areahull = cv2.contourArea(hull)\n",
    "        areacnt = cv2.contourArea(cnt)\n",
    "      \n",
    "    #find the percentage of area not covered by hand in convex hull\n",
    "        arearatio=((areahull-areacnt)/areacnt)*100\n",
    "    \n",
    "     #find the defects in convex hull with respect to hand\n",
    "        hull = cv2.convexHull(approx, returnPoints=False)\n",
    "        defects = cv2.convexityDefects(approx, hull)\n",
    "        \n",
    "    # l = no. of defects\n",
    "        l=0\n",
    "        \n",
    "    #code for finding no. of defects due to fingers\n",
    "        for i in range(defects.shape[0]):\n",
    "            s,e,f,d = defects[i,0]\n",
    "            start = tuple(approx[s][0])\n",
    "            end = tuple(approx[e][0])\n",
    "            far = tuple(approx[f][0])\n",
    "            pt= (100,180)\n",
    "            \n",
    "            \n",
    "            # find length of all sides of triangle\n",
    "            a = math.sqrt((end[0] - start[0])**2 + (end[1] - start[1])**2)\n",
    "            b = math.sqrt((far[0] - start[0])**2 + (far[1] - start[1])**2) \n",
    "            c = math.sqrt((end[0] - far[0])**2 + (end[1] - far[1])**2)\n",
    "            s = (a+b+c)/2\n",
    "            ar = math.sqrt(s*(s-a)*(s-b)*(s-c))\n",
    "            \n",
    "            #distance between point and convex hull\n",
    "            d=(2*ar)/a\n",
    "            \n",
    "            # apply cosine rule here\n",
    "            angle = math.acos((b**2 + c**2 - a**2)/(2*b*c)) * 57\n",
    "            \n",
    "        \n",
    "            # ignore angles > 90 and ignore points very close to convex hull(they generally come due to noise)\n",
    "            if angle <= 90 and d>30:\n",
    "                l += 1\n",
    "                cv2.circle(roi, far, 3, [255,0,0], -1)\n",
    "            \n",
    "            #draw lines around hand\n",
    "            cv2.line(roi,start, end, [0,255,0], 2)\n",
    "            \n",
    "            \n",
    "        l+=1\n",
    "        \n",
    "        #print corresponding gestures which are in their ranges\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        if l==1:\n",
    "            if areacnt<2000:\n",
    "                cv2.putText(frame,'Put hand in the box',(0,50), font, 2, (0,0,255), 3, cv2.LINE_AA)\n",
    "            else:\n",
    "                if arearatio<12:\n",
    "                    cv2.putText(frame,'0',(0,50), font, 2, (0,0,255), 3, cv2.LINE_AA)\n",
    "                elif arearatio<17.5:\n",
    "                    cv2.putText(frame,'Good Job',(0,50), font, 2, (0,0,255), 3, cv2.LINE_AA)\n",
    "                   \n",
    "                else:\n",
    "                    cv2.putText(frame,'1',(0,50), font, 2, (0,0,255), 3, cv2.LINE_AA)\n",
    "                    \n",
    "        elif l==2:\n",
    "            cv2.putText(frame,'2',(0,50), font, 2, (0,0,255), 3, cv2.LINE_AA)\n",
    "            \n",
    "        elif l==3:\n",
    "         \n",
    "              if arearatio<27:\n",
    "                    cv2.putText(frame,'3',(0,50), font, 2, (0,0,255), 3, cv2.LINE_AA)\n",
    "              else:\n",
    "                    cv2.putText(frame,'ok',(0,50), font, 2, (0,0,255), 3, cv2.LINE_AA)\n",
    "                    \n",
    "        elif l==4:\n",
    "            cv2.putText(frame,'4',(0,50), font, 2, (0,0,255), 3, cv2.LINE_AA)\n",
    "            \n",
    "        elif l==5:\n",
    "            cv2.putText(frame,'5',(0,50), font, 2, (0,0,255), 3, cv2.LINE_AA)\n",
    "            \n",
    "        elif l==6:\n",
    "            cv2.putText(frame,'reposition',(0,50), font, 2, (0,0,255), 3, cv2.LINE_AA)\n",
    "            \n",
    "        else :\n",
    "            cv2.putText(frame,'reposition',(10,50), font, 2, (0,0,255), 3, cv2.LINE_AA)\n",
    "            \n",
    "        #show the windows\n",
    "        cv2.imshow('mask',mask)\n",
    "        cv2.imshow('frame',frame)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 2:\n",
    "        break \n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#0B8261; width:100%; height:38px; color:white; font-size:18px; padding:10px;\" id=\"CONCLUSION\">\n",
    "CONCLUSION\n",
    "</div>\n",
    "\n",
    "In the above code we have taken a live video stream and extracted a set of data points which serve as reliably accurate representation of a hand position within a given frame. We can now take this data and train a neural network knowing that the information is highly specific to the problem that we need solving. This will ensure our model maintains top performance and decrease training time. \n",
    "\n",
    "From this example we now have two primary options to further train a neural network. One option is to take the series of coordinates produced by the convex hull wrapped around the hand in our image, in addition to the in number and positions of defects which mark visible fingers, and train a standard network using a straightforward multi-dimensional array as input. This particular solution would offer the simplest and smallest dataset to train our network on, however it may not be detailed enough to represent and recognize complex or nuanced hand gestures. \n",
    "\n",
    "Our second approach would be train a Convolutional neural network using the black and white 'mask' image we have produced in our program which is also displayed at runtime. The benefit of training our neural network using this mask is that the filters of the convolutional network will be able to clearly tell the difference between significant and insignificant data simply by the shade of each pixel.  \n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
